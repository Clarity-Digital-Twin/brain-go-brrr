data:
  batch_size: 256
  cache_index: ${BGB_DATA_ROOT}/cache/tuab_4s_final/index.json
  n_channels: 20
  num_workers: 8
  sampling_rate: 256
  window_duration: 4.0
  window_stride: 2.0
experiment:
  description: Final training with 4s windows
  name: tuab_4s_final
  seed: 42
logging:
  log_interval: 10
  save_best_only: true
model:
  backbone:
    checkpoint_path: ${BGB_DATA_ROOT}/models/eegpt/pretrained/eegpt_mcae_58chs_4s_large4E.ckpt
    freeze: true
    name: eegpt
  probe:
    dropout: 0.3
    hidden_dim: 128
    input_dim: 512
training:
  epochs: 100
  gradient_accumulation: 1
  learning_rate: 0.001
  mixed_precision: true
  patience: 20
  scheduler:
    name: cosine
    warmup_epochs: 2
  weight_decay: 0.01
